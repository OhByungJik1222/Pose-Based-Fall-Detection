{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1dAZfYajKnUV8aPLvQXVSAecTzj0aIUcp","authorship_tag":"ABX9TyMCNztyva5yu990fWRuAxWx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"OMaqfqIEuQ3e"},"outputs":[],"source":["!pip install ultralytics\n","import os\n","import cv2\n","import numpy as np\n","from collections import deque\n","from ultralytics import YOLO\n","import xgboost as xgb\n","from tqdm import tqdm"]},{"cell_type":"code","source":["INPUT_VIDEO  = \"/content/drive/MyDrive/[Projects]/AI Hub/Pose Detection 기반 실시간 낙상 감지 시스템 개발/Data/data/낙상사고 위험동작 영상-센서 쌍 데이터_병원,후면낙상/3.개방데이터/1.데이터/Training/01.원천데이터/TS/영상/Y/SY/00135_H_A_SY_C4/00135_H_A_SY_C4.mp4\"\n","OUTPUT_VIDEO = \"/content/drive/MyDrive/[Projects]/AI Hub/Pose Detection 기반 실시간 낙상 감지 시스템 개발/Data/output_fall_detected_00135_H_A_SY_C4.mp4\"\n","T = 10"],"metadata":{"id":"lRTYO-iCuSOS","executionInfo":{"status":"ok","timestamp":1765874386519,"user_tz":-540,"elapsed":5,"user":{"displayName":"오병직","userId":"04063980640589832756"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["pose_model = YOLO(\"yolov8n-pose.pt\")\n","\n","clf = xgb.XGBClassifier()\n","clf.load_model(\"/content/drive/MyDrive/[Projects]/AI Hub/Pose Detection 기반 실시간 낙상 감지 시스템 개발/fall_xgb.json\")"],"metadata":{"id":"bceLCPILvO2N","executionInfo":{"status":"ok","timestamp":1765874387061,"user_tz":-540,"elapsed":108,"user":{"displayName":"오병직","userId":"04063980640589832756"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["sk_buf   = deque(maxlen=T)\n","bb_buf   = deque(maxlen=T)\n","vid_buf  = deque(maxlen=T)\n","prev_gray = None"],"metadata":{"id":"yFlpnfvJvT0S","executionInfo":{"status":"ok","timestamp":1765874387409,"user_tz":-540,"elapsed":5,"user":{"displayName":"오병직","userId":"04063980640589832756"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["# COCO skeleton pairs\n","SKELETON_EDGES = [\n","    (0,1),(0,2),\n","    (1,3),(2,4),\n","    (5,6),\n","    (5,7),(7,9),\n","    (6,8),(8,10),\n","    (5,11),(6,12),\n","    (11,12),\n","    (11,13),(13,15),\n","    (12,14),(14,16)\n","]"],"metadata":{"id":"pk9Q32T-wZYO","executionInfo":{"status":"ok","timestamp":1765874387756,"user_tz":-540,"elapsed":3,"user":{"displayName":"오병직","userId":"04063980640589832756"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["def video_motion(prev_gray, gray):\n","    if prev_gray is None:\n","        return np.zeros(3)\n","\n","    diff = cv2.absdiff(prev_gray, gray)\n","    mean_diff = np.mean(diff)\n","    max_diff = np.max(diff)\n","\n","    return np.array([\n","        mean_diff / 255.0,\n","        max_diff / 255.0,\n","        np.std(diff) / 255.0\n","    ], dtype=np.float32)\n","\n","\n","def build_feature(sk, bb, vid):\n","    f = []\n","    for x in sk: f.extend(x)\n","    for x in bb: f.extend(x)\n","    f.extend(np.mean(np.array(vid), axis=0))\n","    return np.array(f, dtype=np.float32)\n","\n","def draw_skeleton(frame, kp, conf, conf_th=0.3):\n","    kp = kp.astype(int)\n","\n","    # joint\n","    for i, (x, y) in enumerate(kp):\n","        if conf[i] > conf_th:\n","            cv2.circle(frame, (x, y), 4, (0,255,255), -1)\n","\n","    # bone\n","    for i, j in SKELETON_EDGES:\n","        if conf[i] > conf_th and conf[j] > conf_th:\n","            x1,y1 = kp[i].astype(int)\n","            x2,y2 = kp[j].astype(int)\n","            cv2.line(frame, (x1,y1), (x2,y2), (255,255,0), 2)"],"metadata":{"id":"kxrCdq3rvVkU","executionInfo":{"status":"ok","timestamp":1765874388257,"user_tz":-540,"elapsed":4,"user":{"displayName":"오병직","userId":"04063980640589832756"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["cap = cv2.VideoCapture(INPUT_VIDEO)\n","\n","w = int(cap.get(3))\n","h = int(cap.get(4))\n","fps = cap.get(5)\n","\n","writer = cv2.VideoWriter(\n","    OUTPUT_VIDEO,\n","    cv2.VideoWriter_fourcc(*\"mp4v\"),\n","    fps, (w, h)\n",")"],"metadata":{"id":"XdOn3CoavYQQ","executionInfo":{"status":"ok","timestamp":1765874388757,"user_tz":-540,"elapsed":75,"user":{"displayName":"오병직","userId":"04063980640589832756"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    res = pose_model(frame, verbose=False)[0]\n","\n","    if (\n","        res.keypoints is not None and\n","        res.keypoints.xy is not None and\n","        len(res.keypoints.xy) > 0\n","    ):\n","        kp = res.keypoints.xy[0].cpu().numpy()\n","        conf = res.keypoints.conf[0].cpu().numpy()\n","\n","        draw_skeleton(frame, kp, conf)\n","\n","        sk = np.hstack([kp, conf[:, None]]).flatten()\n","        sk_buf.append(sk)\n","\n","        box = res.boxes.xyxy[0].cpu().numpy()\n","        x1, y1, x2, y2 = map(int, box)\n","        cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n","        bb_buf.append([cx, cy, x2 - x1, y2 - y1, cx / w, cy / h])\n","\n","        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n","\n","    else:\n","        if len(sk_buf) > 0:\n","            sk_buf.append(sk_buf[-1])\n","            bb_buf.append(bb_buf[-1])\n","\n","    # ❗ 사람 없어도 영상 모션은 계속\n","    vid_buf.append(video_motion(prev_gray, gray))\n","    prev_gray = gray\n","\n","    if len(sk_buf) == T:\n","        feat = build_feature(sk_buf, bb_buf, vid_buf)\n","        prob = clf.predict_proba(feat.reshape(1, -1))[0, 1]\n","\n","        label = \"FALL\" if prob > 0.7 else \"NORMAL\"\n","        color = (0, 0, 255) if label == \"FALL\" else (0, 255, 0)\n","\n","        cv2.putText(\n","            frame, f\"{label} {prob:.2f}\",\n","            (30, 50),\n","            cv2.FONT_HERSHEY_SIMPLEX,\n","            1.2, color, 3\n","        )\n","\n","\n","    writer.write(frame)\n"],"metadata":{"id":"mrJU6ZhyvZWC","executionInfo":{"status":"ok","timestamp":1765875426462,"user_tz":-540,"elapsed":17085,"user":{"displayName":"오병직","userId":"04063980640589832756"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["cap.release()\n","writer.release()\n","print(\"✅ Done:\", OUTPUT_VIDEO)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHdp3mQ1vbhm","executionInfo":{"status":"ok","timestamp":1765875445450,"user_tz":-540,"elapsed":11,"user":{"displayName":"오병직","userId":"04063980640589832756"}},"outputId":"7c2eb3d1-b184-4b5d-a036-4aba8ed5558c"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Done: /content/drive/MyDrive/[Projects]/AI Hub/Pose Detection 기반 실시간 낙상 감지 시스템 개발/Data/output_fall_detected_00135_H_A_SY_C4.mp4\n"]}]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"O21rKsHKAvho"}},{"cell_type":"code","source":["INPUT_DIR = \"/content/drive/MyDrive/[Projects]/AI Hub/Pose Detection 기반 실시간 낙상 감지 시스템 개발/Data/data/낙상사고 위험동작 영상-센서 쌍 데이터_병원,후면낙상/3.개방데이터/1.데이터/Validation/01.원천데이터/VS/영상\"\n","\n","OUTPUT_DIR = \"/content/drive/MyDrive/[Projects]/AI Hub/Pose Detection 기반 실시간 낙상 감지 시스템 개발/Data/output_validation\"\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","T = 10\n","THRESH = 0.7"],"metadata":{"id":"zLH03CAHAwL6","executionInfo":{"status":"ok","timestamp":1765853321511,"user_tz":-540,"elapsed":14,"user":{"displayName":"오병직","userId":"04063980640589832756"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["pose_model = YOLO(\"yolov8n-pose.pt\")\n","\n","clf = xgb.XGBClassifier()\n","clf.load_model(\n","    \"/content/drive/MyDrive/[Projects]/AI Hub/Pose Detection 기반 실시간 낙상 감지 시스템 개발/fall_xgb.json\"\n",")"],"metadata":{"id":"i5glHHgLA6yM","executionInfo":{"status":"ok","timestamp":1765852563731,"user_tz":-540,"elapsed":103,"user":{"displayName":"오병직","userId":"04063980640589832756"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["SKELETON_EDGES = [\n","    (0,1),(0,2),\n","    (1,3),(2,4),\n","    (5,6),\n","    (5,7),(7,9),\n","    (6,8),(8,10),\n","    (5,11),(6,12),\n","    (11,12),\n","    (11,13),(13,15),\n","    (12,14),(14,16)\n","]"],"metadata":{"id":"5NOz230WA8fl","executionInfo":{"status":"ok","timestamp":1765852568327,"user_tz":-540,"elapsed":42,"user":{"displayName":"오병직","userId":"04063980640589832756"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["def video_motion(prev_gray, gray):\n","    if prev_gray is None:\n","        return np.zeros(3)\n","    diff = cv2.absdiff(prev_gray, gray)\n","    m = np.mean(diff) / 255.0\n","    return np.array([m, m, m], dtype=np.float32)\n","\n","\n","def build_feature(sk, bb, vid):\n","    f = []\n","    for x in sk: f.extend(x)\n","    for x in bb: f.extend(x)\n","    f.extend(np.mean(np.array(vid), axis=0))\n","    return np.array(f, dtype=np.float32)\n","\n","\n","def draw_skeleton(frame, kp, conf, conf_th=0.3):\n","    kp = kp.astype(int)\n","\n","    for i, (x, y) in enumerate(kp):\n","        if conf[i] > conf_th:\n","            cv2.circle(frame, (x, y), 4, (0,255,255), -1)\n","\n","    for i, j in SKELETON_EDGES:\n","        if conf[i] > conf_th and conf[j] > conf_th:\n","            x1,y1 = kp[i].astype(int)\n","            x2,y2 = kp[j].astype(int)\n","            cv2.line(frame, (x1,y1), (x2,y2), (255,255,0), 2)"],"metadata":{"id":"fhgqKdpiA9oZ","executionInfo":{"status":"ok","timestamp":1765852577155,"user_tz":-540,"elapsed":6,"user":{"displayName":"오병직","userId":"04063980640589832756"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","Y_videos = []\n","N_videos = []\n","\n","for root, _, files in os.walk(INPUT_DIR):\n","    for f in files:\n","        if not f.lower().endswith(\".mp4\"):\n","            continue\n","\n","        full = os.path.join(root, f)\n","\n","        if \"/Y/\" in full:\n","            Y_videos.append(full)\n","        elif \"/N/\" in full:\n","            N_videos.append(full)\n","\n","print(\"Y:\", len(Y_videos), \"N:\", len(N_videos))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7KGqcWevA_yy","executionInfo":{"status":"ok","timestamp":1765853637447,"user_tz":-540,"elapsed":1058,"user":{"displayName":"오병직","userId":"04063980640589832756"}},"outputId":"f70a72db-e36d-4559-c1c4-8071802518dd"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Y: 280 N: 312\n"]}]},{"cell_type":"code","source":["random.seed(2025)\n","\n","Y_sample = random.sample(Y_videos, 5)\n","N_sample = random.sample(N_videos, 5)\n","\n","sample_videos = Y_sample + N_sample\n","\n","for v in sample_videos:\n","    print(v)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rS_F4hGOFC-H","executionInfo":{"status":"ok","timestamp":1765856807151,"user_tz":-540,"elapsed":39,"user":{"displayName":"오병직","userId":"04063980640589832756"}},"outputId":"3bd0477c-f882-4cc7-97cf-fac40d911eb0"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/[Projects]/AI Hub/Pose Detection 기반 실시간 낙상 감지 시스템 개발/Data/data/낙상사고 위험동작 영상-센서 쌍 데이터_병원,후면낙상/3.개방데이터/1.데이터/Validation/01.원천데이터/VS/영상/Y/SY/00079_H_A_SY_C4/00079_H_A_SY_C4.mp4\n","/content/drive/MyDrive/[Projects]/AI Hub/Pose Detection 기반 실시간 낙상 감지 시스템 개발/Data/data/낙상사고 위험동작 영상-센서 쌍 데이터_병원,후면낙상/3.개방데이터/1.데이터/Validation/01.원천데이터/VS/영상/Y/SY/02547_H_D_SY_C5/02547_H_D_SY_C5.mp4\n","/content/drive/MyDrive/[Projects]/AI Hub/Pose Detection 기반 실시간 낙상 감지 시스템 개발/Data/data/낙상사고 위험동작 영상-센서 쌍 데이터_병원,후면낙상/3.개방데이터/1.데이터/Validation/01.원천데이터/VS/영상/Y/SY/00274_H_D_SY_C1/00274_H_D_SY_C1.mp4\n","/content/drive/MyDrive/[Projects]/AI Hub/Pose Detection 기반 실시간 낙상 감지 시스템 개발/Data/data/낙상사고 위험동작 영상-센서 쌍 데이터_병원,후면낙상/3.개방데이터/1.데이터/Validation/01.원천데이터/VS/영상/Y/SY/02659_H_A_SY_C7/02659_H_A_SY_C7.mp4\n","/content/drive/MyDrive/[Projects]/AI Hub/Pose Detection 기반 실시간 낙상 감지 시스템 개발/Data/data/낙상사고 위험동작 영상-센서 쌍 데이터_병원,후면낙상/3.개방데이터/1.데이터/Validation/01.원천데이터/VS/영상/Y/SY/00001_H_A_SY_C1/00001_H_A_SY_C1.mp4\n","/content/drive/MyDrive/[Projects]/AI Hub/Pose Detection 기반 실시간 낙상 감지 시스템 개발/Data/data/낙상사고 위험동작 영상-센서 쌍 데이터_병원,후면낙상/3.개방데이터/1.데이터/Validation/01.원천데이터/VS/영상/N/N/02209_H_A_N_C7/02209_H_A_N_C7.mp4\n","/content/drive/MyDrive/[Projects]/AI Hub/Pose Detection 기반 실시간 낙상 감지 시스템 개발/Data/data/낙상사고 위험동작 영상-센서 쌍 데이터_병원,후면낙상/3.개방데이터/1.데이터/Validation/01.원천데이터/VS/영상/N/N/02228_H_A_N_C1/02228_H_A_N_C1.mp4\n","/content/drive/MyDrive/[Projects]/AI Hub/Pose Detection 기반 실시간 낙상 감지 시스템 개발/Data/data/낙상사고 위험동작 영상-센서 쌍 데이터_병원,후면낙상/3.개방데이터/1.데이터/Validation/01.원천데이터/VS/영상/N/N/02510_H_A_N_C4/02510_H_A_N_C4.mp4\n","/content/drive/MyDrive/[Projects]/AI Hub/Pose Detection 기반 실시간 낙상 감지 시스템 개발/Data/data/낙상사고 위험동작 영상-센서 쌍 데이터_병원,후면낙상/3.개방데이터/1.데이터/Validation/01.원천데이터/VS/영상/N/N/00599_H_D_N_C7/00599_H_D_N_C7.mp4\n","/content/drive/MyDrive/[Projects]/AI Hub/Pose Detection 기반 실시간 낙상 감지 시스템 개발/Data/data/낙상사고 위험동작 영상-센서 쌍 데이터_병원,후면낙상/3.개방데이터/1.데이터/Validation/01.원천데이터/VS/영상/N/N/00204_H_D_N_C1/00204_H_D_N_C1.mp4\n"]}]},{"cell_type":"code","source":["for input_path in tqdm(sample_videos):\n","    video_name = os.path.basename(input_path)\n","    output_path = os.path.join(\n","        OUTPUT_DIR,\n","        video_name.replace(\".mp4\", \"_fall_detected.mp4\")\n","    )\n","\n","    cap = cv2.VideoCapture(input_path)\n","    if not cap.isOpened():\n","        print(f\"❌ Failed to open {video_name}\")\n","        continue\n","\n","    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","    writer = cv2.VideoWriter(\n","        output_path,\n","        cv2.VideoWriter_fourcc(*\"mp4v\"),\n","        fps, (w, h)\n","    )\n","\n","    sk_buf  = deque(maxlen=T)\n","    bb_buf  = deque(maxlen=T)\n","    vid_buf = deque(maxlen=T)\n","    prev_gray = None\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","        res = pose_model(frame, verbose=False)[0]\n","\n","        if res.keypoints is not None and len(res.keypoints.xy) > 0:\n","            kp = res.keypoints.xy[0].cpu().numpy()\n","            conf = res.keypoints.conf[0].cpu().numpy()\n","\n","            draw_skeleton(frame, kp, conf)\n","\n","            sk = np.hstack([kp, conf[:, None]]).flatten()\n","            sk_buf.append(sk)\n","\n","            box = res.boxes.xyxy[0].cpu().numpy()\n","            x1,y1,x2,y2 = map(int, box)\n","            cx, cy = (x1+x2)/2, (y1+y2)/2\n","            bb_buf.append([cx, cy, x2-x1, y2-y1, cx/w, cy/h])\n","\n","            cv2.rectangle(frame,(x1,y1),(x2,y2),(255,0,0),2)\n","\n","        vid_buf.append(video_motion(prev_gray, gray))\n","        prev_gray = gray\n","\n","        if len(sk_buf) == T:\n","            feat = build_feature(sk_buf, bb_buf, vid_buf)\n","            prob = clf.predict_proba(feat.reshape(1,-1))[0,1]\n","\n","            label = \"FALL\" if prob > THRESH else \"NORMAL\"\n","            color = (0,0,255) if label==\"FALL\" else (0,255,0)\n","\n","            cv2.putText(\n","                frame,\n","                f\"{label} {prob:.2f}\",\n","                (30,50),\n","                cv2.FONT_HERSHEY_SIMPLEX,\n","                1.2,\n","                color,\n","                3\n","            )\n","\n","        writer.write(frame)\n","\n","    cap.release()\n","    writer.release()\n","\n","print(\"✅ All validation videos processed\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k4LfBSSiBAvg","executionInfo":{"status":"ok","timestamp":1765857005165,"user_tz":-540,"elapsed":196540,"user":{"displayName":"오병직","userId":"04063980640589832756"}},"outputId":"4828d2bc-b3fd-461c-d726-b800a4a20dba"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [03:16<00:00, 19.65s/it]"]},{"output_type":"stream","name":"stdout","text":["✅ All validation videos processed\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}